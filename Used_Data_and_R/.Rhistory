library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(splines)
library(tidymodels)
tidymodels_prefer()
COVID_State <- read.csv("COVID - State - Daily.csv", na.strings = ".")
Employment_State <- read.csv("Employment - State - Daily.csv", na.strings = ".")
Mobility_State <- read.csv("Google Mobility - State - Daily.csv", na.strings = ".")
Spending_State <- read.csv("Affinity - State - Daily.csv", na.strings = ".")
COVID_State$Date<-as.Date(with(COVID_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Employment_State$Date<-as.Date(with(Employment_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Mobility_State$Date<-as.Date(with(Mobility_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Spending_State$Date<-as.Date(with(Spending_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
full_data <- merge(merge(merge(COVID_State, Employment_State, by=c("Date","statefips")), Mobility_State, by=c("Date","statefips")), Spending_State, by=c("Date","statefips"))
head(full_data)
full_data1 <- full_data %>%
select(-year.x, -month.x, -day.x, - year.y, -month.y, -day.y, -year.x )
minnesota <- full_data1 %>%
filter(statefips==27)
#OLS
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
full_rec <- recipe(gps_away_from_home ~  fullvaccine_rate + case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_model_wf <- workflow() %>%
add_recipe(full_rec) %>%
add_model(lm_spec)
#CV is to see how well the model is doing
mnFullMod_cv <- fit_resamples(mn_model_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv %>% collect_metrics(summarize=TRUE)
mn_mod <- mn_model_wf %>% fit(data=minnesota)
#LASSO
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_lasso_spec <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_lasso_rec <- recipe(gps_away_from_home ~  fullvaccine_rate + case_rate + hospitalized_rate  + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_lasso_wf_tune <- workflow() %>%
add_recipe(full_lasso_rec) %>%
add_model(lm_lasso_spec)
# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
penalty(range = c(-15, -2)), #log10 transformed 10^-5 to 10^3
levels = 30)
tune_res <- tune_grid( # new function for tuning parameters
mn_lasso_wf_tune, # workflow
resamples = folded_mn, # cv folds
metrics = metric_set(rmse, rsq, mae),
grid = penalty_grid # penalty grid defined above
)
# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_res) + theme_classic()
# Summarize Model Evaluation Metrics (CV)
collect_metrics(tune_res) %>%
filter(.metric == 'rmse') %>% # or choose mae
select(penalty, rmse = mean)
best_penalty <- select_best(tune_res, metric = 'rmse') # choose penalty value based on lowest mae or rmse
# Fit Final Model
final_wf <- finalize_workflow(mn_lasso_wf_tune, best_penalty) # incorporates penalty value to workflow
final_fit <- fit(final_wf, data = minnesota)
tidy(final_fit)
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123) # Pick your favorite number to fill in the parentheses
# Lasso Model Spec
lm_lasso_spec <-
linear_reg() %>%
set_args(mixture = 1, penalty = 0) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
# Recipe with standardization (!)
#data_rec <- recipe( ___ ~ ___ , data = ___) %>%
#step_nzv(all_predictors()) %>% # removes variables with the same value
#step_novel(all_nominal_predictors()) %>% # important if you have rare categorical variables
#step_normalize(all_numeric_predictors()) %>%  # important standardization step for LASSO
#step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
# Workflow (Recipe + Model)
#lasso_wf <- workflow() %>%
#add_recipe(data_rec) %>%
#add_model(lm_lasso_spec)
# Fit Model
#lasso_fit <- lasso_wf %>%
#fit(data = ___) # Fit to data
plot(lasso_fit %>% extract_fit_parsnip() %>% pluck('fit'), # way to get the original glmnet output
xvar = "lambda") # glmnet fits the model with a variety of lambda penalty values
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123) # Pick your favorite number to fill in the parentheses
# Lasso Model Spec
lm_lasso_spec <-
linear_reg() %>%
set_args(mixture = 1, penalty = 0) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
# Recipe with standardization (!)
#data_rec <- recipe( ___ ~ ___ , data = ___) %>%
#step_nzv(all_predictors()) %>% # removes variables with the same value
#step_novel(all_nominal_predictors()) %>% # important if you have rare categorical variables
#step_normalize(all_numeric_predictors()) %>%  # important standardization step for LASSO
#step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
# Workflow (Recipe + Model)
#lasso_wf <- workflow() %>%
#add_recipe(data_rec) %>%
#add_model(lm_lasso_spec)
# Fit Model
#lasso_fit <- lasso_wf %>%
#fit(data = ___) # Fit to data
plot(lasso_fit %>% extract_fit_parsnip() %>% pluck('fit'), # way to get the original glmnet output
xvar = "lambda") # glmnet fits the model with a variety of lambda penalty values
tune_output %>% collect_metrics() %>% filter(penalty == (best_se_penalty %>% pull(penalty)))
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
cars2018 <- read_csv("https://raw.githubusercontent.com/juliasilge/supervised-ML-case-studies-course/master/data/cars2018.csv")
head(cars2018)
# Cleaning
cars2018 <- cars2018 %>%
select(-model_index)
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
full_rec <- recipe(mpg ~ ., data = cars2018) %>%
update_role(model, new_role = 'ID') %>% # we want to keep the name of the car model but not as a predictor or outcome
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>% # important standardization step for LASSO
step_dummy(all_nominal_predictors())  # creates indicator variables for categorical variables
full_lm_wf <- workflow() %>%
add_recipe(full_rec) %>%
add_model(lm_spec)
full_model <- fit(full_lm_wf, data = cars2018)
full_model %>% tidy()
set.seed(123)
MPG_cv <- vfold_cv(cars2018, v=10)
cars_cv <- fit_resamples(full_lm_wf,
resamples = MPG_cv,
metrics = metric_set(mae))
cars_cv %>% unnest(.metrics)
# Tune and fit a LASSO model to the data (with CV)
set.seed(74)
# Create CV folds
data_cv10 <- vfold_cv(cars2018, v = 10)
# Lasso Model Spec with tune
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
# Workflow (Recipe + Model)
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
penalty(range = c(-3, 1)), #log10 transformed
levels = 30)
tune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = data_cv10, # cv folds
metrics = metric_set(rmse, mae),
grid = penalty_grid # penalty grid defined above
)
# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_output) + theme_classic()
metrics_output <- collect_metrics(tune_output) %>%
filter(.metric == 'mae')
ggplot(metrics_output, aes(x=penalty, y=mean))+
geom_point()+
geom_line()
best_penalty <- select_best(tune_output, metric = 'mae') # choose penalty value based on lowest cv mae
best_penalty
best_se_penalty <- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty)) # choose largest penalty value within 1 se of the lowest cv mae
best_se_penalty
# Fit Final Model
final_wf <- finalize_workflow(lasso_wf_tune, best_penalty) # incorporates penalty value to workflow
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow
final_fit <- fit(final_wf, data = cars2018)
final_fit_se <- fit(final_wf_se, data = cars2018)
tidy(final_fit)
tidy(final_fit_se)
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8))
# Obtain the predictors and coefficients of the "best" model
# Filter out the coefficient are 0
final_fit_se %>% tidy() %>% filter(estimate != 0)
tune_output %>% collect_metrics() %>% filter(penalty == (best_se_penalty %>% pull(penalty)))
lasso_mod_out <- final_fit_se %>%
predict(new_data = cars2018) %>%
bind_cols(cars2018) %>%
mutate(resid = mpg - .pred)
#Residual Plots
#OLS
mn_mod_output <- mn_mod %>%
predict(new_data = minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output, aes(y = resid, x = .pred)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#LASSO
mn_mod_output_lasso <- final_fit %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
library(ISLR)
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(splines)
library(tidymodels)
tidymodels_prefer()
COVID_State <- read.csv("COVID - State - Daily.csv", na.strings = ".")
Employment_State <- read.csv("Employment - State - Daily.csv", na.strings = ".")
Mobility_State <- read.csv("Google Mobility - State - Daily.csv", na.strings = ".")
Spending_State <- read.csv("Affinity - State - Daily.csv", na.strings = ".")
COVID_State$Date<-as.Date(with(COVID_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Employment_State$Date<-as.Date(with(Employment_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Mobility_State$Date<-as.Date(with(Mobility_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Spending_State$Date<-as.Date(with(Spending_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
full_data <- merge(merge(merge(COVID_State, Employment_State, by=c("Date","statefips")), Mobility_State, by=c("Date","statefips")), Spending_State, by=c("Date","statefips"))
head(full_data)
full_data1 <- full_data %>%
select(-year.x, -month.x, -day.x, - year.y, -month.y, -day.y, -year.x )
minnesota <- full_data1 %>%
filter(statefips==27)
#OLS
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
full_rec <- recipe(gps_away_from_home ~  fullvaccine_rate + case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_model_wf <- workflow() %>%
add_recipe(full_rec) %>%
add_model(lm_spec)
#CV is to see how well the model is doing
mnFullMod_cv <- fit_resamples(mn_model_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv %>% collect_metrics(summarize=TRUE)
mn_mod <- mn_model_wf %>% fit(data=minnesota)
#LASSO
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_lasso_spec <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_lasso_rec <- recipe(gps_away_from_home ~  fullvaccine_rate + case_rate + hospitalized_rate  + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_lasso_wf_tune <- workflow() %>%
add_recipe(full_lasso_rec) %>%
add_model(lm_lasso_spec)
# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
penalty(range = c(-15, -2)), #log10 transformed 10^-5 to 10^3
levels = 30)
tune_res <- tune_grid( # new function for tuning parameters
mn_lasso_wf_tune, # workflow
resamples = folded_mn, # cv folds
metrics = metric_set(rmse, rsq, mae),
grid = penalty_grid # penalty grid defined above
)
# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_res) + theme_classic()
# Summarize Model Evaluation Metrics (CV)
collect_metrics(tune_res) %>%
filter(.metric == 'rmse') %>% # or choose mae
select(penalty, rmse = mean)
best_penalty <- select_best(tune_res, metric = 'rmse') # choose penalty value based on lowest mae or rmse
# Fit Final Model
final_wf <- finalize_workflow(mn_lasso_wf_tune, best_penalty) # incorporates penalty value to workflow
final_fit <- fit(final_wf, data = minnesota)
tidy(final_fit)
#Residual Plots
#OLS
mn_mod_output <- mn_mod %>%
predict(new_data = minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output, aes(y = resid, x = .pred)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#LASSO
mn_mod_output_lasso <- final_fit %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output_lasso, aes(y = resid, x = hospitalized_rate)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#COEFFICIENT PATHS
final_fit %>% tidy() %>% filter(estimate != 0)
mn_mod_output_lasso <- final_fit %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
#COEFFICIENT PATHS
glmnet_output <- final_fit %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8))
best_penalty <- select_best(tune_res, metric = 'mae') # choose penalty value based on lowest cv mae
best_penalty
best_se_penalty <- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty))
#COEFFICIENT PATHS
best_penalty <- select_best(tune_res, metric = 'mae') # choose penalty value based on lowest cv mae
best_penalty
best_se_penalty <- select_by_one_std_err(tune_output, metric = 'mae', desc(penalty))
glmnet_output <- final_fit %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8))
#COEFFICIENT PATHS
best_penalty <- select_best(tune_res, metric = 'mae') # choose penalty value based on lowest cv mae
best_penalty
best_se_penalty <- select_by_one_std_err(tune_res, metric = 'mae', desc(penalty))
glmnet_output <- final_fit %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8))
glmnet_output <- final_fit %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8))
#COEFFICIENT PATHS
best_penalty <- select_best(tune_res, metric = 'mae') # choose penalty value based on lowest cv mae
best_penalty
best_se_penalty <- select_by_one_std_err(tune_res, metric = 'mae', desc(penalty))
#CHOOSING PREDICTORS
final_fit %>% tidy() %>% filter(estimate != 0)
#LASSO
mn_mod_output_lasso <- final_fit %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output_lasso, aes(y = resid, x = hospitalized_rate)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#Residual Plots
#OLS
mn_mod_output <- mn_mod %>%
predict(new_data = minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output, aes(y = resid, x = .pred)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#LASSO
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_lasso_spec <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso, we'll choose penalty later
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_lasso_rec <- recipe(gps_away_from_home ~  fullvaccine_rate + case_rate + hospitalized_rate  + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_lasso_wf_tune <- workflow() %>%
add_recipe(full_lasso_rec) %>%
add_model(lm_lasso_spec)
# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
penalty(range = c(-15, -2)), #log10 transformed 10^-5 to 10^3
levels = 30)
tune_res <- tune_grid( # new function for tuning parameters
mn_lasso_wf_tune, # workflow
resamples = folded_mn, # cv folds
metrics = metric_set(rmse, rsq, mae),
grid = penalty_grid # penalty grid defined above
)
# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_res) + theme_classic()
# Summarize Model Evaluation Metrics (CV)
collect_metrics(tune_res) %>%
filter(.metric == 'rmse') %>% # or choose mae
select(penalty, rmse = mean)
best_penalty <- select_best(tune_res, metric = 'rmse') # choose penalty value based on lowest mae or rmse
# Fit Final Model
final_wf <- finalize_workflow(mn_lasso_wf_tune, best_penalty) # incorporates penalty value to workflow
final_fit <- fit(final_wf, data = minnesota)
tidy(final_fit)
