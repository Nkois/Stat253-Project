geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = case_rate)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq1)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq2)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq3)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq4)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = spend_remoteservices)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
knitr::opts_chunk$set(echo = TRUE)
mn_mod_output_OLS <- mn_mod %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
knitr::opts_chunk$set(echo = TRUE)
# library statements
# read in data
library(ISLR)
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(splines)
library(tidymodels)
tidymodels_prefer()
COVID_State <- read.csv("COVID - State - Daily.csv", na.strings = ".")
Employment_State <- read.csv("Employment - State - Daily.csv", na.strings = ".")
Mobility_State <- read.csv("Google Mobility - State - Daily.csv", na.strings = ".")
Spending_State <- read.csv("Affinity - State - Daily.csv", na.strings = ".")
# data cleaning
COVID_State$Date<-as.Date(with(COVID_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Employment_State$Date<-as.Date(with(Employment_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Mobility_State$Date<-as.Date(with(Mobility_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
Spending_State$Date<-as.Date(with(Spending_State,paste(year,month,day,sep="-")),"%Y-%m-%d")
full_data <- merge(merge(merge(COVID_State, Employment_State, by=c("Date","statefips")), Mobility_State, by=c("Date","statefips")), Spending_State, by=c("Date","statefips"))
head(full_data)
full_data1 <- full_data %>%
select(-year.x, -month.x, -day.x, - year.y, -month.y, -day.y, -year.x )
# Creating a Dummy Variable that is yes from entry 22 to 50, the period of dramatic change.
full_data1 <- mutate(full_data1, dummy_spend_fall = if_else(Date >= "2020-03-16" & Date <= "2020-04-13", 1, 0))
minnesota <- full_data1 %>%
filter(statefips==27)
ggplot(minnesota, aes(y = gps_away_from_home, x = Date)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(minnesota, aes(y = dummy_spend_fall, x = Date)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
#OLS
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
full_rec <- recipe(gps_away_from_home ~ case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
full_rec_dummy <- recipe(gps_away_from_home ~ case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices + dummy_spend_fall, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_model_wf <- workflow() %>%
add_recipe(full_rec) %>%
add_model(lm_spec)
mn_model_dumy_wf <- workflow() %>%
add_recipe(full_rec_dummy) %>%
add_model(lm_spec)
#CV is to see how well the model is doing
mnFullMod_cv <- fit_resamples(mn_model_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv %>% collect_metrics(summarize=TRUE)
mn_mod <- mn_model_wf %>% fit(data=minnesota)
#with Dummy fo dramatic drop in spending
mnFullMod_cv_dumy <- fit_resamples(mn_model_dumy_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv_dumy %>% collect_metrics(summarize=TRUE)
mn_mod_dummy <- mn_model_dumy_wf %>% fit(data=minnesota)
mn_mod_output_OLS <- mn_mod %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
mn_mod_output_OLS <- mn_mod_dummy %>%
predict(new_data=minnesota) %>%
bind_cols(minnesota)%>%
mutate(resid = gps_away_from_home - .pred)
ggplot(mn_mod_output_OLS, aes(y = resid, x = hospitalized_rate)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = case_rate)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq1)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq2)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq3)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = emp_incq4)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
ggplot(mn_mod_output_OLS, aes(y = resid, x = spend_remoteservices)) +
geom_point() +
geom_smooth(color = "blue", se = FALSE) +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
mn_mod_dummy <- mn_model_dumy_wf %>% fit(data=minnesota)
mnFullMod_cv_dumy %>% collect_metrics(summarize=TRUE)
mn_mod <- mn_model_wf %>% fit(data=minnesota)
mnFullMod_cv %>% collect_metrics(summarize=TRUE)
mn_mod_dummy <- mn_model_dumy_wf %>% fit(data=minnesota)
#OLS
set.seed(123)
folded_mn <- vfold_cv(minnesota, v = 6)
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
full_rec <- recipe(gps_away_from_home ~ case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
full_rec_dummy <- recipe(gps_away_from_home ~ case_rate + hospitalized_rate + emp_incq1 + emp_incq2 + emp_incq3 + emp_incq4 + spend_remoteservices + dummy_spend_fall, data=minnesota) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())%>%
step_nzv(all_predictors())
mn_model_wf <- workflow() %>%
add_recipe(full_rec) %>%
add_model(lm_spec)
mn_model_dumy_wf <- workflow() %>%
add_recipe(full_rec_dummy) %>%
add_model(lm_spec)
#CV is to see how well the model is doing
mnFullMod_cv <- fit_resamples(mn_model_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv %>% collect_metrics(summarize=TRUE)
mn_mod <- mn_model_wf %>% fit(data=minnesota)
#with Dummy fo dramatic drop in spending
mnFullMod_cv_dumy <- fit_resamples(mn_model_dumy_wf,
resamples = folded_mn,
control = control_resamples(save_pred = TRUE),
metrics = metric_set(rmse, rsq, mae))
mnFullMod_cv_dumy %>% collect_metrics(summarize=TRUE)
mn_mod_dummy <- mn_model_dumy_wf %>% fit(data=minnesota)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(probably) #install.packages('probably')
install.packages('probably')
library(dplyr)
library(ggplot2)
library(tidymodels)
library(probably)
tidymodels_prefer()
set.seed(2048) # Pick your favorite number to fill in the parentheses
# Make sure you set reference level (the outcome you are NOT interested in)
data <- data %>%
mutate(outcome = relevel(outcome, ref='failure')) #set reference level
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(probably)
tidymodels_prefer()
set.seed(2048) # Pick your favorite number to fill in the parentheses
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(probably)
tidymodels_prefer()
set.seed(2048) # Pick your favorite number to fill in the parentheses
# Make sure you set reference level (the outcome you are NOT interested in)
data <- data %>%
mutate(outcome = relevel(outcome, ref='failure')) #set reference level
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(probably)
tidymodels_prefer()
set.seed(2048) # Pick your favorite number to fill in the parentheses
# Make sure you set reference level (the outcome you are NOT interested in)
data <- data %>%
mutate(outcome = relevel(outcome, ref=)) #set reference level
library(dplyr)
library(readr)
library(ggplot2)
library(tidymodels)
library(probably) #install.packages('probably')
tidymodels_prefer()
spam <- read_csv("https://www.dropbox.com/s/leurr6a30f4l32a/spambase.csv?dl=1")
ggplot(spam, aes(x = char_freq_exclam, y = word_freq_george)) +
geom_boxplot()
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam)) +
geom_boxplot()
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george)) +
geom_boxplot()
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george, y = char_freq_exclam)) +
geom_line()
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george, y = char_freq_exclam)) +
geom_point()
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george, y = char_freq_exclam)) +
geom_point() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
# Make sure you set reference level (to the outcome you are NOT interested in)
spam <- spam %>%
mutate(spam = relevel(factor(spam), ref='not spam')) #set reference level
# Logistic Regression Model Spec
logistic_spec <- logistic_reg() %>%
set_engine('glm') %>%
set_mode('classification')
# Recipe
logistic_rec <- recipe(spam ~ word_freq_george + char_freq_exclam, data = spam)
# Workflow (Recipe + Model)
log_wf <- workflow() %>%
add_recipe(logistic_rec) %>%
add_model(logistic_spec)
# Fit Model
log_fit <- fit(log_wf, data = spam)
View(spam)
tidy(log_fit)
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam, y = spam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george, y = spam)) +
geom_boxplot()
ggplot(spam, aes(x = word_freq_george, y = char_freq_exclam)) +
geom_point() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
exp(-7.3927109)
exp(2.1077374)
tidy(log_fit)
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.0025 + 2.1077374 * 0.01
# odds
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.0025 + 2.1077374 * 0.01
# odds
exp(-0.631191)
?return
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.0025 + 2.1077374 * 0.01
# odds
exp(-0.631191)
# Probability (AKA soft prediction)
exp(-0.631191) / (1 + exp(-0.631191))
# Hard prediction
predict('not spam', new_data = data.frame(word_freq_george = 0.25, char_freq_exclam = 1), type = spam)
?predict
predict(log_fit, new_data = data.frame(word_freq_george = 0.25, char_freq_exclam = 1), type = spam)
predict(log_fit, new_data = data.frame(word_freq_george = 0.25, char_freq_exclam = 1), type = 'not spam')
predict(log_fit, new_data = data.frame(word_freq_george = 0.25, char_freq_exclam = 1), type = 'prob')
# Soft predictions
logistic_output <-  spam %>%
bind_cols(predict(log_fit, new_data = spam, type = 'prob'))
head(logistic_output)
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.25 + 2.1077374 * 1
# odds
exp(-0.631191)
# Probability (AKA soft prediction)
exp(-0.631191) / (1 + exp(-0.631191))
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.25 + 2.1077374 * 1
# odds
exp(-0.631191)
# Probability (AKA soft prediction)
exp(-0.631191) / (1 + exp(-0.631191))
# Probability (AKA soft prediction)
exp(-0.3742269) / (1 + exp(-0.3742269))
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.25 + 2.1077374 * 1
# odds
exp(-0.3742269)
# Probability (AKA soft prediction)
exp(-0.3742269) / (1 + exp(-0.3742269))
View(spam)
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.25 + 2.1077374 * 1
# odds
exp(-0.3742269)
# Probability (AKA soft prediction)
exp(-0.3742269) / (1 + exp(-0.3742269))
summary(spam)
# Probability (AKA soft prediction)
exp(-0.3742269) / (1 + exp(-0.3742269))
tidy(log_fit)
# log odds
-0.6337866 + -7.3927109 * 0.25 + 2.1077374 * 1
# odds
exp(-0.3742269)
# Probability (AKA soft prediction)
exp(-0.3742269) / (1 + exp(-0.3742269))
# If you want to adjust the axis limits, you can add the following to your plot:
# + coord_cartesian(ylim = c(0,1))
# + coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = char_freq_exclam, y = spam)) +
geom_boxplot() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = word_freq_george, y = spam)) +
geom_boxplot() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
ggplot(spam, aes(x = word_freq_george, y = char_freq_exclam)) +
geom_point() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
# Soft predictions
logistic_output <-  spam %>%
bind_cols(predict(log_fit, new_data = spam, type = 'prob'))
head(logistic_output)
ggplot(logistic_output, aes(x = .pred_spam, y = spam)) +
geom_boxplot() +
coord_cartesian(ylim = c(0,1)) +
coord_cartesian(xlim = c(0,1))
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
#accuracy: accuracy = chance of correctly predicting outcome
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
#accuracy: accuracy = chance of correctly predicting outcome
(2721 + 413)/(4601)
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
413/(413 + 67)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
2721/(1400 + 2721)
#accuracy: accuracy = chance of correctly predicting outcome
(2721 + 413)/(4601)
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
67/(413 + 67)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
2721/(1400 + 2721)
#accuracy: accuracy = chance of correctly predicting outcome
(2721 + 413)/(4601)
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
413/(413 + 1400)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
2721/(1400 + 2721)
#accuracy: accuracy = chance of correctly predicting outcome
(2721 + 413)/(4601)
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
# Hard predictions (you pick threshold)
logistic_output <- logistic_output %>%
mutate(.pred_class = make_two_class_pred(`.pred_not spam`, levels(spam), threshold = 0.3))
# Confusion Matrix
logistic_output %>%
conf_mat(truth = spam, estimate = .pred_class)
# Calculate them by hand first and then confirm below
#sens: sensitivity = chance of correctly predicting second level, given second level (Spam)
413/(413 + 1400)
#spec: specificity = chance of correctly predicting first level, given first level (Not Spam)
2721/(67 + 2721)
#accuracy: accuracy = chance of correctly predicting outcome
(2721 + 413)/(4601)
log_metrics <- metric_set(sens, yardstick::spec, accuracy)
logistic_output %>%
log_metrics(estimate = .pred_class, truth = spam, event_level = "second")
logistic_roc <- logistic_output %>%
roc_curve(spam, .pred_spam, event_level = "second")
autoplot(logistic_roc) + theme_classic()
logistic_output %>%
roc_auc(spam, .pred_spam, event_level = "second")
set.seed(123)
data_cv10 <- vfold_cv(spam, v = 10)
# CV Fit Model
log_cv_fit <- fit_resamples(
log_wf,
resamples = data_cv10,
metrics = metric_set(sens, yardstick::spec, accuracy, roc_auc),
control = control_resamples(save_pred = TRUE, event_level = 'second'))  # you need predictions for ROC calculations
collect_metrics(log_cv_fit) #default threshold is 0.5
